
## GitHub Actions Data Pipeline

We're creating a Python pipeline using [GitHub Actions](https://docs.github.com/en/actions) to add support for map layers with 30,000+ records, similar to Hack for LA's [Public Tree Map](https://neighborhood.org/public-tree-map/). 



1. Generate a fresh dataset with our [Python for filling in gaps in industry data](https://github.com/modelearth/machine-learning/) - we're publishing an article in Applied Science.

2. Generate data for comparison using the imputed CBP data from by Fabian Ecker, et al. (2018, 2021) which expands upon the Isserman and Westervelt (2006) work using a linear objective function. 
The authors write: "After 1994, the CBP files contain tabulations at the zip code level. We plan to apply our imputation method to this geographic unit in a future draft."  [View PDF](http://fpeckert.me/cbp/efsy.pdf) and [Resulting data through 2016](http://www.fpeckert.me/cbp/)

3. Working with BuildingTransparency.org API data for [label templates](../../../io/template/)

---

Process [All the Places](https://www.alltheplaces.xyz/) into zip folders in our [zip/io/data repo](https://model.earth/zip/io/)<!-- generated by Kathryn Winglee. -->.  
Here's our example of [pulling and uncompressing the places file](https://github.com/modelearth/alltheplaces_curl) into a repo.

We are now pulling CSV files froom Google Sheets every 5 minutes in the [Python Pipeline](https://github.com/modelearth/python-pipeline) set up by Dan van Kley.  

[Learn about our Data Setup](../../../localsite/info/data) and view a sample Display Datasets using Tabular.

To Do: Trigger our [FarmFresh Python](https://github.com/modelearth/community-data/tree/master/process/python/farmfresh) data pull nightly from a Github Action.  
Updates for [Farm Fresh - Federal USDA location data](../../farmfresh) on maps - initially merged for Aglanta.  


**Our GitHub Actions samples**  
[Generate Environmental Impact Profile Labels](../../../apps/impact) - Abrie  
[Scrape Wikipedia state carbon footprints](https://github.com/abrie/beyond-carbon-scraper) - Abrie  
[Scrape city website and save JSON file using Python](https://github.com/abrie/atl-council-scraper) - Abrie  
[Pull from PDF to a CSV file using R script](https://github.com/bbrewington/ga.dph.data) - Brant and Abrie  
[Python Pipeline - Google Sheets to CSV](https://github.com/modelearth/python-pipeline) - Dan van Kley